From Chaston et al., 2003:
"We also exclude those events where high time resolution, or burst electron data with full 2-D electron distributions at 80 ms is not available.".
->We have been doing no such screening. What is the purpose of it?
     ->This would clearly relate to what Bob Ergun talked about—availability of data only during times corresponding to high activity (flux, etc.)

From Harvey et al., 2001:
3.4.4. Survey and Quick-Look Telemetry Management (VC4 and VC3)
In order to provide a large-scale context for the high-rate burst data snapshots (see Section 3.4.5), a
‘survey data’ collection scheme was implemented. Survey data are generated by all the instruments during
science data collection, either by averaging the data or by filtering the output of analog signals before
digitization. Two different survey data collection rates, termed fast survey and slow survey, are used to
optimize the science. Fast survey data collection rates (∼0.5 Mbit s−1) are about an order of magnitude higher
than slow survey rates (<0.05 Mbit s−1) and about an order of magnitude lower than high-rate burst data
collection (∼5–12Mbit s−1, see Section 3.4.5.). Onboard data evaluation schemes determine which survey
collection rate to use and a memory management scheme prevents survey memory overflow (described below). In
addition, survey data can be stored in two separate memory buffers (VC3 and VC4) which have different readout
priorities and are used to enhance real-time science operations. The VC3 and VC4 segments are independent
circular FIFO buffers providing comprehensive storage of survey science data. While VC4 provides the bulk of
the storage, VC3 is intended for quick-look datasets during telemetry contacts. By simply directing a subset
of the survey data to an empty VC3 buffer, users can avoid waiting for VC4 to empty before getting real-time
survey data.

In addition to storing and playing survey data, the VC4 manager is responsible for switching the IDPU between
Fast and Slow survey modes. The concept is simple: whenever the trigger value ‘Flevel’ exceeds the commanded
threshold, a transition to Fast survey data collection mode is initiated. To prevent memory overflow and
trigger oscillations, a memory management scheme was implemented as outlined below.

First, in order to prevent the system from simply filling up all of the survey buffers with a few minutes of
Fast survey data, leaving no room to complete the orbit, the VC4 manager limits Fast survey data collection to
a commandable ‘FSALLOC’ page limit. The page limit is set by stored command after each data dump, with page
limit allocations calculated by the science operations center based upon contact schedules and data collection
periods (see McFadden et al., 2001). The Fast survey page limit is implemented by maintaining a bitmap of the
VC4 memory, indicating which pages are Fast Survey data and which are Slow Survey data, and keeping track of
how much Fast survey is in memory at a given time as data is collected and telemetered.

Second, to prevent system oscillation between Fast and Slow survey data collection during contacts where the
data is being simultaneously collected and transmitted, software limits the transition rate. These
oscillations would happen when the Fast survey data collection rate exceeds the telemetry rate, and the Slow
survey collection rate is below the telemetry rate. For example, the system would go into Fast mode, filling
the VC4 memory until it hits the FSALLOC limit, switch to Slow mode allowing the telemetry to catch up, then
quickly switch back to Fast mode. To limit this switching, the software allows Slow-to-Fast transitions only
if there is 1/8th of the FSALLOC memory available for Fast survey data. Third, in order to prevent
oscillations between Fast and Slow modes caused by fluctuations in the Flevel trigger calculations, the
software only allows transitions to Slow mode when the Flevel falls below the threshold for 20 s. Hysteresis
in this decision could have been employed, except the performance would have depended on filtering
characteristics, which was judged more difficult than simple timing. Once the software has decided to switch
between Fast and Slow modes, the actual implementation is quite easy. The Slow-to-Fast and Fast-to-Slow
transitions are simply command strings set in memory and maintained by ‘mode’ definitions (see Section 3.3.3),
so the VC4 manager merely instructs the command module to execute one of the strings.

3.4.5. Burst Telemetry Management (VC2)
The most complex of the storage areas is VC2 memory. It can operate as either a circular FIFO like VC3 and
VC4, or as a collection of smaller ‘burst’ memories. When operated in ‘burst’ mode, the memory is subdivided
into N +1 Search areas and N Collect areas, where N is up to 64. Search areas are used to store data before a
triggered event and Collect areas contain data sampled after the event. For each burst collection, there is a
16-bit ‘science merit’ evaluation of the data within that collection called EVALMAX. This value is calculated
by a weighted average of the Burst ‘Goodness’ or ‘Bgood’ value during the Search and Collect periods. ‘Bgood’
is evaluated from trigger inputs, with an algorithm similar to the trigger algorithm as described below in
Section 3.4.6.  To start a burst collection, the flight software finds the open Search area and directs all
VC2 data sampling into that area of memory. At 10 Hz, the Burst trigger level or ‘Blevel’ parameter is
calculated and compared to the minimum of the EVALMAX values for all other stored bursts which are not
currently being transmitted. If the ‘Blevel’ seen during the Search period exceeds the EVALMAX value of
another burst, then that burst is selected to be overwritten. Flight software directs all new VC2 data into
the overwritten burst’s Collect area of memory.When the Collection area is filled, the EVALMAXparameter is
calculated and the process begins again.

Flight software selects bursts to be played out on a ‘best-first’ policy, and, for simplification, does not
retract a decision once made. Thus, it is possible that N great events show up during the playing of a less
interesting event, and that only N − 1 can be stored. Given a large enough ‘N’, however, this should be very
unlikely. FAST typically operates with N = 5 which gives bursts with about 10 s durations.

3.4.6. Trigger Calculations
Among other things, the IDPU software has to distinguish interesting data from uninteresting data. This is
accomplished by applying a pair of user-selected algorithms, called BSALG and FSALG, which control Burst
collections and Fast Survey mode, respectively. The user selects which two functions to use, consistent with
the planned mode of the instrument, from a library of available functions. These include eight electric field
inputs; four electric field functions that combine the electric field inputs to trigger on AKR, Electrostatic
Shocks, VLF, etc.; and three ESA functions to trigger on electron and ion counting rates or on a function that
tracks the energy with the highest counting rate.

Software executes BSALG and FSALG every 64th of a spin (about 13 times per second), and filters the outputs
using three slope-sensitive 16-bit infinite response digital filters, producing the quantities BGood, BLevel,
and FLevel. Each filter responds to rising signals with different parameters from falling signals, allowing
users to make filters that have both good sensitivity and long retention. BGood is a longer averaged version
of BLevel, and the two are used by the Burst manager in the determination of burst collection quality (see
Section 3.4.5). Similarly, Flevel is used by the Survey manager to determine Fast survey data collection (see
Section 3.4.4).

In order to avoid false triggers during mode transitions and power switching, the module includes an inhibit
timer which is usually set by the start of a mode. While active, this clears Flevel and Blevel so that no
Bursts or Fast survey modes are activated. In addition, trigger calculations are disabled during both electric
field diagnostic sweeps and during trigger algorithm changes. The trigger packet provides engineering
diagnostic data needed to identify ‘interesting’ regions. Basically all of the available raw trigger data is
provided along with the filtered results of two selected functions. Thus, even if the selected functions do
not trigger on interesting regions, the raw data can be used to determine which functions would have
triggered.
